from __future__ import annotations
import requests
import base64
import io
import json
import logging
import os
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime

from google.adk.agents.llm_agent import Agent
from google.adk.tools import FunctionTool, ToolContext
from google.adk.tools.transfer_to_agent_tool import transfer_to_agent
from google.cloud import storage
from pydantic import BaseModel, Field

# --- Dependencies ---
try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

# --- Logging ---
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# --- GCS ì„¤ì • ---
# í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ (ê¸°ë³¸ê°’ ì—†ìŒ - ë°˜ë“œì‹œ .envì—ì„œ ì„¤ì •í•´ì•¼ í•¨)
GCS_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME")
PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT")

if not GCS_BUCKET_NAME or not PROJECT_ID:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ GCS_BUCKET_NAMEê³¼ GOOGLE_CLOUD_PROJECTë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")

try:
    # ë°°í¬ í™˜ê²½ì—ì„œë„ ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œì íŠ¸ ì§€ì •
    storage_client = storage.Client(project=PROJECT_ID)
    logger.info(f"â˜ï¸ GCS ë²„í‚·: {GCS_BUCKET_NAME}")
    logger.info(f"ğŸ“Œ í”„ë¡œì íŠ¸: {PROJECT_ID}")
except Exception as e:
    logger.warning(f"âš ï¸ GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    storage_client = None


# =============================================================================
# GCS ì €ì¥ í•¨ìˆ˜
# =============================================================================

def save_to_gcs(
    data: Dict[str, Any], 
    filename: str, 
    folder: str = "interview_questions"
) -> Optional[str]:
    """
    GCSì— JSON ë°ì´í„° ì €ì¥
    
    Args:
        data: ì €ì¥í•  ë°ì´í„° (ë”•ì…”ë„ˆë¦¬)
        filename: íŒŒì¼ëª… (ì˜ˆ: "interview_questions_user123_20251027.json")
        folder: GCS ë‚´ í´ë”ëª… (ê¸°ë³¸ê°’: "interview_questions")
    
    Returns:
        GCS URI (gs://interview-data-cosmic-mariner/...) ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    logger.info(f"ğŸ” save_to_gcs ì‹œì‘: {folder}/{filename}")
    
    if not storage_client:
        logger.warning("âš ï¸ GCS í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ GCS ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    try:
        logger.info(f"ğŸ“¦ ë²„í‚· ì—°ê²° ì¤‘: {GCS_BUCKET_NAME}")
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        
        logger.info(f"ğŸ“ Blob ìƒì„± ì¤‘: {folder}/{filename}")
        blob = bucket.blob(f"{folder}/{filename}")
        
        # JSON ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œ
        json_string = json.dumps(data, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“Š JSON í¬ê¸°: {len(json_string):,} bytes")
        
        logger.info(f"â¬†ï¸ GCS ì—…ë¡œë“œ ì‹œì‘...")
        blob.upload_from_string(
            json_string,
            content_type="application/json"
        )
        logger.info(f"â¬†ï¸ GCS ì—…ë¡œë“œ ì™„ë£Œ")
        
        gcs_uri = f"gs://{GCS_BUCKET_NAME}/{folder}/{filename}"
        logger.info(f"âœ… GCS ì €ì¥ ì™„ë£Œ: {gcs_uri}")
        
        return gcs_uri
        
    except Exception as e:
        logger.error(f"âŒ GCS ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"âŒ ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        import traceback
        logger.error(f"âŒ ìƒì„¸ ìŠ¤íƒ:\n{traceback.format_exc()}")
        return None


# =============================================================================
# TOOLS
# =============================================================================

# === TOOLS ===

# --- Tool 1: Resume Loading ---
class ResumeContentRequest(BaseModel):
    """ìê¸°ì†Œê°œì„œ ë¡œë”© ìš”ì²­"""
    pdf_base64: Optional[str] = Field(None, description="Base64 ì¸ì½”ë”©ëœ PDF")
    file_path: Optional[str] = Field(None, description="ë¡œì»¬ íŒŒì¼ ê²½ë¡œ")
    fallback_text: Optional[str] = Field(None, description="ì§ì ‘ ì…ë ¥í•œ í…ìŠ¤íŠ¸")

class ResumeContent(BaseModel):
    """ìê¸°ì†Œê°œì„œ ë‚´ìš©"""
    resume_text: str = Field(..., description="ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
    page_count: int = Field(..., description="í˜ì´ì§€ ìˆ˜")

def load_resume_content(
    pdf_base64: Optional[str] = None,
    file_path: Optional[str] = None, 
    fallback_text: Optional[str] = None
) -> Dict[str, Any]:
    """ìê¸°ì†Œê°œì„œ PDF ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        pdf_base64: Base64 ì¸ì½”ë”©ëœ PDF ë°ì´í„°
        file_path: PDF íŒŒì¼ ê²½ë¡œ (gs://, http(s)://, ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ)
                   - gs://bucket/path/file.pdf (GCS URI - ê¶Œì¥)
                   - http(s)://... (Presigned URL - ë ˆê±°ì‹œ)
                   - /local/path/file.pdf (ë¡œì»¬ íŒŒì¼)
        fallback_text: ì§ì ‘ ì…ë ¥í•œ í…ìŠ¤íŠ¸
        
    Returns:
        Dict containing resume_text and page_count
    """
    
    if pdf_base64:
        if not PdfReader:
            raise RuntimeError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        try:
            pdf_bytes = base64.b64decode(pdf_base64)
            reader = PdfReader(io.BytesIO(pdf_bytes))
            text = "\n".join(page.extract_text() or "" for page in reader.pages).strip()
            if not text:
                raise RuntimeError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"resume_text": text, "page_count": len(reader.pages)}
        except Exception as e:
            raise RuntimeError(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    # 2. GCS URIì—ì„œ PDF ë‹¤ìš´ë¡œë“œ (gs://bucket/path í˜•ì‹)
    if file_path and file_path.startswith("gs://"):
        if not PdfReader:
            raise RuntimeError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not storage_client:
            raise RuntimeError("GCS í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            logger.info(f"ğŸ“¥ GCSì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {file_path}")
            
            # gs://bucket-name/path/to/file.pdf â†’ bucket-name, path/to/file.pdf
            gcs_path = file_path.replace("gs://", "")
            bucket_name, blob_path = gcs_path.split("/", 1)
            
            logger.info(f"ğŸª£ ë²„í‚·: {bucket_name}, ê²½ë¡œ: {blob_path}")
            
            bucket = storage_client.bucket(bucket_name)
            blob = bucket.blob(blob_path)
            
            # PDF ë‹¤ìš´ë¡œë“œ
            pdf_bytes = blob.download_as_bytes()
            logger.info(f"âœ… PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(pdf_bytes):,} bytes")
            
            # PDF íŒŒì‹±
            reader = PdfReader(io.BytesIO(pdf_bytes))
            text = "\n".join(page.extract_text() or "" for page in reader.pages).strip()
            if not text:
                raise RuntimeError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text):,} ë¬¸ì, {len(reader.pages)} í˜ì´ì§€")
            return {"resume_text": text, "page_count": len(reader.pages)}
            
        except Exception as e:
            logger.error(f"âŒ GCS PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise RuntimeError(f"GCSì—ì„œ PDF ë‹¤ìš´ë¡œë“œ/ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    # 3. HTTP(S) URLì—ì„œ PDF ë‹¤ìš´ë¡œë“œ (Presigned URL ë“± - ë ˆê±°ì‹œ ì§€ì›)
    if file_path and (file_path.startswith("http://") or file_path.startswith("https://")):
        if not PdfReader:
            raise RuntimeError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        try:
            logger.info(f"ğŸ“¥ URLì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {file_path[:80]}...")
            response = requests.get(file_path, timeout=60)
            response.raise_for_status()
            
            pdf_bytes = response.content
            logger.info(f"âœ… PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(pdf_bytes):,} bytes")
            
            reader = PdfReader(io.BytesIO(pdf_bytes))
            text = "\n".join(page.extract_text() or "" for page in reader.pages).strip()
            if not text:
                raise RuntimeError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text):,} ë¬¸ì, {len(reader.pages)} í˜ì´ì§€")
            return {"resume_text": text, "page_count": len(reader.pages)}
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"URLì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        except Exception as e:
            raise RuntimeError(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    if file_path:
        if not PdfReader:
            raise RuntimeError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        try:
            with open(file_path, "rb") as f:
                reader = PdfReader(f)
                text = "\n".join(page.extract_text() or "" for page in reader.pages).strip()
                if not text:
                    raise RuntimeError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {"resume_text": text, "page_count": len(reader.pages)}
        except Exception as e:
            raise RuntimeError(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    if fallback_text:
        text = fallback_text.strip()
        if not text:
            raise RuntimeError("ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return {"resume_text": text, "page_count": 1}
    
    raise RuntimeError("PDF, íŒŒì¼ ê²½ë¡œ, ë˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")

load_resume_tool = FunctionTool(func=load_resume_content)


# --- Tool 2: Company Research Request (Google SearchëŠ” Agentê°€ ì§ì ‘ ìˆ˜í–‰) ---
def request_company_research(
    company_name: str,
    search_type: str = "overview"
) -> Dict[str, Any]:
    """ê¸°ì—… ì¡°ì‚¬ ìš”ì²­ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì œ ì›¹ ê²€ìƒ‰ì€ Agentì˜ Google Search Groundingì´ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        company_name: ì¡°ì‚¬í•  ê¸°ì—…ëª…
        search_type: ì¡°ì‚¬ ìœ í˜• (overview, talent_philosophy, core_values, vision, business)
        
    Returns:
        Dict containing research request information
    """
    
    logger.info(f"ğŸ” ê¸°ì—… ì¡°ì‚¬ ìš”ì²­: {company_name} - {search_type}")
    
    # ê²€ìƒ‰ ê°€ì´ë“œ ë©”ì‹œì§€
    research_guides = {
        "overview": f"{company_name}ì˜ ì „ë°˜ì ì¸ ì •ë³´ (ì¸ì¬ìƒ, í•µì‹¬ê°€ì¹˜, ë¹„ì „, ì‚¬ì—…ë¶„ì•¼)",
        "talent_philosophy": f"{company_name}ì˜ ì¸ì¬ìƒê³¼ ì±„ìš© ì •ë³´",
        "core_values": f"{company_name}ì˜ í•µì‹¬ ê°€ì¹˜ì™€ ê¸°ì—… ë¬¸í™”",
        "vision": f"{company_name}ì˜ ë¹„ì „, ë¯¸ì…˜, ê²½ì˜ ì² í•™",
        "business": f"{company_name}ì˜ ì£¼ìš” ì‚¬ì—… ë¶„ì•¼ì™€ ì œí’ˆ/ì„œë¹„ìŠ¤"
    }
    
    guide = research_guides.get(search_type, f"{company_name}ì— ëŒ€í•œ ì •ë³´")
    
    return {
        "company_name": company_name,
        "search_type": search_type,
        "research_guide": guide,
        "instruction": f"ì›¹ì—ì„œ '{guide}'ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”. ê³µì‹ í™ˆí˜ì´ì§€ì™€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì„¸ìš”.",
        "status": "ready_for_search"
    }

company_research_tool = FunctionTool(func=request_company_research)


# --- Tool 2-1: Search Google (ë”ë¯¸ ë„êµ¬ - ëª¨ë¸ì´ ëª…ì‹œì ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰) ---
def search_google(query: str) -> str:
    """
    Google ê²€ìƒ‰ ë„êµ¬ - ëª¨ë¸ì´ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì‹¤ì œ ê²€ìƒ‰ì€ Geminiì˜ ë‚´ì¥ Google Search Groundingì´ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        
    Returns:
        ê²€ìƒ‰ ê°€ì´ë“œ ë©”ì‹œì§€
    """
    logger.info(f"ğŸ” Google ê²€ìƒ‰ ìš”ì²­: {query}")
    return f"'{query}'ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”. Google Search Groundingì„ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ì°¾ê³ , ê³µì‹ ì¶œì²˜ URLì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."

search_google_tool = FunctionTool(func=search_google)




# --- Tool 4: Save Resume Analysis (ìê¸°ì†Œê°œì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥) ---
def save_resume_analysis(
    summary: str,
    experiences: List[Dict[str, Any]],
    technical_skills: List[str],
    soft_skills: List[str],
    achievements: List[str],
    interests: List[str],
    personality_traits: List[str],
    keywords: List[str],
    company_name: str,
    session_id: str
) -> Dict[str, Any]:
    """ìê¸°ì†Œê°œì„œ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ GCSì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        summary: í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥)
        experiences: ì£¼ìš” ê²½í—˜ ë¦¬ìŠ¤íŠ¸ [{"title": "í”„ë¡œì íŠ¸ëª…", "description": "ì„¤ëª…", "achievements": "ì„±ê³¼", "skills_used": [...]}]
        technical_skills: ê¸°ìˆ  ì—­ëŸ‰ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ROS, Python, C++)
        soft_skills: ì†Œí”„íŠ¸ ìŠ¤í‚¬ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: íŒ€ì›Œí¬, ë¬¸ì œí•´ê²°)
        achievements: ì£¼ìš” ì„±ê³¼ ë¦¬ìŠ¤íŠ¸
        interests: ê´€ì‹¬ ë¶„ì•¼ ë¦¬ìŠ¤íŠ¸
        personality_traits: ì„±ê²©/ê°€ì¹˜ê´€ ë¦¬ìŠ¤íŠ¸
        keywords: í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        company_name: ì§€ì› ê¸°ì—…ëª…
        session_id: ì„¸ì…˜ ID (ì˜ˆ: session_20251107_160000)
        
    Returns:
        Dict confirming data was saved with file path
    """
    
    # âœ… íŒŒì¼ëª…ì— ì„¸ì…˜ ID ì‚¬ìš©
    gcs_filename = f"{session_id}_analysis.json"
    
    # ì €ì¥í•  ë°ì´í„° êµ¬ì¡° (êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼)
    analysis_data = {
        "sessionId": session_id,
        "company_name": company_name,
        "timestamp": datetime.now().isoformat(),
        "resume_analysis": {
            "summary": summary,
            "experiences": experiences,
            "technical_skills": technical_skills,
            "soft_skills": soft_skills,
            "achievements": achievements,
            "interests": interests,
            "personality_traits": personality_traits,
            "keywords": keywords
        },
        "company_info": None,  # ë‚˜ì¤‘ì— company_researcherê°€ ì—…ë°ì´íŠ¸
        "created_by": "interview_agent_adk"
    }
    
    # GCSì— ì €ì¥
    gcs_uri = save_to_gcs(analysis_data, gcs_filename, folder="interview_questions")
    
    if gcs_uri is None:
        logger.error(f"âŒ GCS ì €ì¥ ì‹¤íŒ¨!")
        return {
            "status": "error",
            "message": "GCS ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            "gcs_uri": None,
            "filename": None
        }
    
    logger.info(f"âœ… ìê¸°ì†Œê°œì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {gcs_filename}")
    logger.info(f"   ì„¸ì…˜ ID: {session_id}")
    
    return {
        "status": "success",
        "message": f"ìê¸°ì†Œê°œì„œ ë¶„ì„ì´ ì™„ë£Œë˜ê³  GCSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "sessionId": session_id,
        "gcs_uri": gcs_uri,
        "filename": gcs_filename
    }

save_resume_analysis_tool = FunctionTool(func=save_resume_analysis)


# --- Tool 5: Update Company Info (ê¸°ì—… ì •ë³´ ì—…ë°ì´íŠ¸) ---
def update_company_info(
    session_id: str,
    talent_philosophy: List[str],
    core_values: List[str],
    vision: str,
    business_areas: List[str]
) -> Dict[str, Any]:
    """ìê¸°ì†Œê°œì„œ ë¶„ì„ íŒŒì¼ì— ê¸°ì—… ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        session_id: ì„¸ì…˜ ID (ì˜ˆ: session_20251107_160000)
        talent_philosophy: ì¸ì¬ìƒ ë¦¬ìŠ¤íŠ¸
        core_values: í•µì‹¬ ê°€ì¹˜ ë¦¬ìŠ¤íŠ¸
        vision: ë¹„ì „/ë¯¸ì…˜
        business_areas: ì‚¬ì—… ë¶„ì•¼ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        Dict confirming update was successful
    """
    
    if not storage_client:
        return {
            "status": "error",
            "message": "GCS í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }
    
    try:
        # âœ… ì„¸ì…˜ IDë¡œ íŒŒì¼ëª… ìƒì„±
        filename = f"{session_id}_analysis.json"
        
        # GCSì—ì„œ ê¸°ì¡´ íŒŒì¼ ë¡œë“œ
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        blob_path = f"interview_questions/{filename}"
        blob = bucket.blob(blob_path)
        
        if not blob.exists():
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {blob_path}")
            return {
                "status": "error",
                "message": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}"
            }
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = json.loads(blob.download_as_text())
        
        # ê¸°ì—… ì •ë³´ ì¶”ê°€
        existing_data["company_info"] = {
            "talent_philosophy": talent_philosophy,
            "core_values": core_values,
            "vision": vision,
            "business_areas": business_areas
        }
        existing_data["updated_at"] = datetime.now().isoformat()
        
        # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
        blob.upload_from_string(
            json.dumps(existing_data, ensure_ascii=False, indent=2),
            content_type="application/json"
        )
        
        logger.info(f"âœ… ê¸°ì—… ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {filename}")
        
        return {
            "status": "success",
            "message": "ê¸°ì—… ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "gcs_uri": f"gs://{GCS_BUCKET_NAME}/{blob_path}",
            "filename": filename
        }
        
    except Exception as e:
        logger.error(f"âŒ ê¸°ì—… ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return {
            "status": "error",
            "message": f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}"
        }

update_company_info_tool = FunctionTool(func=update_company_info)


# === AGENTS ===

# --- Single Root Agent (í†µí•© ë²„ì „ - ì†ë„ ìµœì í™”) ---
root_agent = Agent(
    name="multi_agent_interview_system",
    model="gemini-2.5-flash",
    description="AI ë©´ì ‘ ì‹œìŠ¤í…œì„ ì´ê´„ ê´€ë¦¬í•˜ëŠ” ì½”ë””ë„¤ì´í„° ì—ì´ì „íŠ¸ (Gemini Function Calling ê¸°ë°˜)",
    instruction="""
ğŸ¯ **ë˜‘í„°ë·° AI ë©´ì ‘ ì¤€ë¹„ ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!** ğŸ¯

ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œì™€ ê¸°ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë©´ì ‘ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**âš¡ ì¤‘ìš”: ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ìˆ˜í–‰í•˜ì„¸ìš”! (Sub-agent ì „ë‹¬ ê¸ˆì§€)**

**ğŸ†” ì„¸ì…˜ ID ì¶”ì¶œ (ìµœìš°ì„ !):**
ë©”ì‹œì§€ì—ì„œ ì„¸ì…˜ IDë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
```
[SESSION_ID: session_20251107_160000]
```
ì¶”ì¶œí•œ ì„¸ì…˜ IDë¥¼ ëª¨ë“  í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì‚¬ìš©í•˜ì„¸ìš”!

**ì‘ì—… ìˆœì„œ (ë°˜ë“œì‹œ ìˆœì°¨ì ìœ¼ë¡œ):**

**1ë‹¨ê³„: ìê¸°ì†Œê°œì„œ ë¡œë“œ ë° ë¶„ì„**
   a) `load_resume_content()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìê¸°ì†Œê°œì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ì„¸ìš”
      - ë©”ì‹œì§€ì—ì„œ "GCS URI: gs://..." í˜•ì‹ì˜ URIë¥¼ ì°¾ìœ¼ì„¸ìš”
      - ì´ GCS URIë¥¼ `file_path` ì¸ìë¡œ ì „ë‹¬í•˜ì„¸ìš”
      - ì˜ˆ: `load_resume_content(file_path="gs://interview-data-cosmic-mariner/pdf/session_xxx_resume.pdf")`
   
   b) ìê¸°ì†Œê°œì„œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
      - ì§€ì› ê¸°ì—…ëª… (í•„ìˆ˜!)
      - í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥)
      - ì£¼ìš” ê²½í—˜/í”„ë¡œì íŠ¸ (êµ¬ì¡°í™”):
        [{"title": "í”„ë¡œì íŠ¸ëª…", "description": "ì„¤ëª…", "achievements": "ì„±ê³¼", "skills_used": [...]}]
      - ê¸°ìˆ  ì—­ëŸ‰ (technical_skills): ["ROS", "Python", ...]
      - ì†Œí”„íŠ¸ ìŠ¤í‚¬ (soft_skills): ["íŒ€ì›Œí¬", "ë¬¸ì œí•´ê²°", ...]
      - ì£¼ìš” ì„±ê³¼ (achievements): ["ì„±ê³¼1", "ì„±ê³¼2", ...]
      - ê´€ì‹¬ ë¶„ì•¼ (interests): ["ë¡œë´‡ ê³µí•™", ...]
      - ì„±ê²©/ê°€ì¹˜ê´€ (personality_traits): ["ë„ì „ì ", ...]
      - í•µì‹¬ í‚¤ì›Œë“œ (keywords): ["ë¡œë´‡", "ë¬´ì¸ì²´ê³„", ...]
   
   c) âœ… `save_resume_analysis()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ GCSì— ì €ì¥í•˜ì„¸ìš”:
      ```
      save_resume_analysis(
          summary="...",
          experiences=[...],
          technical_skills=[...],
          soft_skills=[...],
          achievements=[...],
          interests=[...],
          personality_traits=[...],
          keywords=[...],
          company_name="LIG Nex1",
          session_id="session_20251107_160000"  # â† ì¶”ì¶œí•œ ì„¸ì…˜ ID!
      )
      ```
   
   d) ë°˜í™˜ëœ **sessionId**ë¥¼ ê¸°ì–µí•˜ì„¸ìš”!

**2ë‹¨ê³„: ê¸°ì—… ì •ë³´ ì›¹ ê²€ìƒ‰**
   a) 1ë‹¨ê³„ì—ì„œ ì¶”ì¶œí•œ **ê¸°ì—…ëª…**ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”:
      - "[ê¸°ì—…ëª…] ì¸ì¬ìƒ ì±„ìš© ê³µì‹"
      - "[ê¸°ì—…ëª…] í•µì‹¬ê°€ì¹˜ ê¸°ì—…ë¬¸í™” ê³µì‹"
      - "[ê¸°ì—…ëª…] ë¹„ì „ ë¯¸ì…˜ ê³µì‹"
      - "[ê¸°ì—…ëª…] ì‚¬ì—…ë¶„ì•¼ ì£¼ìš”ì‚¬ì—…"
   
   b) ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
      - ì¸ì¬ìƒ (talent_philosophy): 3-5ê°œ
      - í•µì‹¬ ê°€ì¹˜ (core_values): 3-5ê°œ
      - ë¹„ì „/ë¯¸ì…˜ (vision): 1ê°œ
      - ì‚¬ì—… ë¶„ì•¼ (business_areas): 2-4ê°œ
   
   c) âœ… `update_company_info()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê¸°ì—… ì •ë³´ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:
      ```
      update_company_info(
          session_id="session_20251107_160000",  # â† ì¶”ì¶œí•œ ì„¸ì…˜ ID!
          talent_philosophy=[...],
          core_values=[...],
          vision="...",
          business_areas=[...]
      )
      ```

**3ë‹¨ê³„: ì™„ë£Œ ë©”ì‹œì§€**
   "âœ… ìê¸°ì†Œê°œì„œ ë¶„ì„ ë° ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! GCSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."

**ğŸš¨ ì ˆëŒ€ ê¸ˆì§€:**
- âŒ transfer_to_agent ì‚¬ìš© ê¸ˆì§€
- âŒ sub-agentì—ê²Œ ì‘ì—… ìœ„ì„ ê¸ˆì§€
- âŒ ë‹¹ì‹ ì´ ì§ì ‘ ëª¨ë“  í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”!

**ğŸ“‹ ìµœì¢… ë°ì´í„° êµ¬ì¡°:**
```json
{
  "company_name": "LIG Nex1",
  "resume_analysis": {
    "summary": "...",
    "experiences": [...],
    "technical_skills": [...],
    "soft_skills": [...],
    "achievements": [...],
    "interests": [...],
    "personality_traits": [...],
    "keywords": [...]
  },
  "company_info": {
    "talent_philosophy": [...],
    "core_values": [...],
    "vision": "...",
    "business_areas": [...]
  }
}
```

ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì…¨ë‚˜ìš”? ğŸ“„âœ¨
""",
    sub_agents=[],  # âœ… Sub-agent ì œê±°
    tools=[
        load_resume_tool,
        save_resume_analysis_tool,
        search_google_tool,
        company_research_tool,
        update_company_info_tool
    ],
    include_contents="default",
)